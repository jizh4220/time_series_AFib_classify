{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:14:09.392334: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-20 11:14:09.395969: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 11:14:09.434496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-20 11:14:09.434540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-20 11:14:09.435853: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-20 11:14:09.443331: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-20 11:14:09.443951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-20 11:14:10.516131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from heartkit.tasks import TaskFactory\n",
    "from typing import Type, TypeVar\n",
    "from argdantic import ArgField, ArgParser\n",
    "from pydantic import BaseModel\n",
    "from heartkit.utils import env_flag, set_random_seed, setup_logger\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "from heartkit.tasks.AFIB_Ident.utils import (\n",
    "    create_model,\n",
    "    load_datasets,\n",
    "    load_test_datasets,\n",
    "    load_train_datasets,\n",
    "    prepare,\n",
    ")\n",
    "\n",
    "from heartkit.defines import (\n",
    "    HKDemoParams\n",
    ")\n",
    "from heartkit.tasks.AFIB_Ident.defines import (\n",
    "    get_class_mapping,\n",
    "    get_class_names,\n",
    "    get_class_shape,\n",
    "    get_classes,\n",
    "    get_feat_shape,\n",
    ")\n",
    "\n",
    "cli = ArgParser()\n",
    "B = TypeVar(\"B\", bound=BaseModel)\n",
    "\n",
    "\n",
    "def parse_content(cls: Type[B], content: str) -> B:\n",
    "    \"\"\"Parse file or raw content into Pydantic model.\n",
    "\n",
    "    Args:\n",
    "        cls (B): Pydantic model subclasss\n",
    "        content (str): File path or raw content\n",
    "\n",
    "    Returns:\n",
    "        B: Pydantic model subclass instance\n",
    "    \"\"\"\n",
    "    if os.path.isfile(content):\n",
    "        with open(content, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "    return cls.model_validate_json(json_data=content)\n",
    "\n",
    "\n",
    "config = '../configs/arrhythmia-100class-2.json'\n",
    "params = parse_content(HKDemoParams, config)\n",
    "\n",
    "\n",
    "params.seed = set_random_seed(params.seed)\n",
    "params.data_parallelism = 8\n",
    "\n",
    "class_names = get_class_names(params.num_classes)\n",
    "class_map = get_class_mapping(params.num_classes)\n",
    "input_spec = (\n",
    "    tf.TensorSpec(shape=get_feat_shape(params.frame_size), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=get_class_shape(params.frame_size, params.num_classes), dtype=tf.int32),\n",
    ")\n",
    "# since now we are getting one minute for every frame so it should be 400 / 100 * 15 = 60 seconds\n",
    "datasets = load_datasets(\n",
    "    ds_path=params.ds_path,\n",
    "    frame_size=params.frame_size * 15,\n",
    "    sampling_rate=params.sampling_rate,\n",
    "    class_map=class_map,\n",
    "    spec=input_spec,\n",
    "    datasets=params.datasets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from heartkit.rpc.backends import EvbBackend, PcBackend\n",
    "from IPython.display import clear_output\n",
    "from heartkit.tasks.AFIB_Ident.utils import (\n",
    "    create_model,\n",
    "    load_datasets,\n",
    "    load_test_datasets,\n",
    "    load_train_datasets,\n",
    "    prepare,\n",
    ")\n",
    "\n",
    "from enum import IntEnum\n",
    "from heartkit.defines import (\n",
    "    HKDemoParams, HeartBeat, HeartRate, HeartRhythm, HeartSegment\n",
    ")\n",
    "\n",
    "from heartkit.tasks.AFIB_Ident.defines import (\n",
    "    get_class_mapping,\n",
    "    get_class_names,\n",
    "    get_class_shape,\n",
    "    get_classes,\n",
    "    get_feat_shape,\n",
    ")\n",
    "\n",
    "class IcentiaRhythm(IntEnum):\n",
    "    \"\"\"Icentia rhythm labels\"\"\"\n",
    "    noise = 0\n",
    "    normal = 1\n",
    "    afib = 2\n",
    "    aflut = 3\n",
    "    end = 4\n",
    "\n",
    "HeartRhythmMap = {\n",
    "    IcentiaRhythm.noise: HeartRhythm.noise,\n",
    "    IcentiaRhythm.normal: HeartRhythm.normal,\n",
    "    IcentiaRhythm.afib: HeartRhythm.afib,\n",
    "    IcentiaRhythm.aflut: HeartRhythm.aflut,\n",
    "    IcentiaRhythm.end: HeartRhythm.noise,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_prediction(\n",
    "        # patient_id,\n",
    "        fig: go.Figure,\n",
    "        ts,\n",
    "        sub_x: np.ndarray,\n",
    "        y_pred: np.ndarray, \n",
    "        y_orig: np.ndarray,\n",
    "        class_names: List[str],\n",
    "        color_dict: Dict[int, str],\n",
    "        row_idx: int = 1,\n",
    "):\n",
    "\n",
    "    primary_color = \"#11acd5\"\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(0, sub_x.shape[0], params.frame_size), desc=\"Inference\"):\n",
    "        if i % (5*params.frame_size) == 0:\n",
    "            # start a new row for the make_plots\n",
    "            row_idx += 1\n",
    "\n",
    "        if i + params.frame_size > sub_x.shape[0]:\n",
    "            start, stop = sub_x.shape[0] - params.frame_size, sub_x.shape[0]\n",
    "        else:\n",
    "            start, stop = i, i + params.frame_size\n",
    "\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=ts[start] + (ts[stop-1] - ts[start]) / 2,\n",
    "            y=np.min(x)*0.8,\n",
    "            text=class_names[y_pred[start]],\n",
    "            showarrow=False,\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            font=dict(color=color_dict[y_pred[start]]),\n",
    "        )\n",
    "\n",
    "        # predicted results\n",
    "        fig.add_vrect(\n",
    "            x0=ts[start],\n",
    "            x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "            y0=np.min(x)/3+0.2,\n",
    "            # y1=np.max(x[start:stop]) / 2,\n",
    "            y1=np.min(x)/3,  \n",
    "            fillcolor=color_dict[y_pred[start]],\n",
    "            opacity=0.25,\n",
    "            line_width=0,\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "        # original results\n",
    "        fig.add_annotation(\n",
    "            x=ts[start] + (ts[stop-1] - ts[start]) / 2,\n",
    "            y=np.max(x),\n",
    "            text=class_names[y_orig[i // 400]],\n",
    "            showarrow=False,\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            font=dict(color=color_dict[y_orig[i // 400]]),\n",
    "        )\n",
    "\n",
    "        fig.add_vrect(\n",
    "            x0=ts[start],\n",
    "            x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "            # y0=np.max(x)/2,\n",
    "            y0=0.9,\n",
    "            # y1=np.max(x)*0.8,  \n",
    "            y1=1.1,\n",
    "            fillcolor=color_dict[y_orig[i // 400]],\n",
    "            opacity=0.25,\n",
    "            line_width=0,\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "       \n",
    "           # predction != original\n",
    "        if y_pred[start] != y_orig[i // 400]:\n",
    "            fig.add_vrect(\n",
    "                x0=ts[start],\n",
    "                x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "                y0=0.9,\n",
    "                y1=1.1,\n",
    "                fillcolor=\"red\",\n",
    "                opacity=0.25,\n",
    "                line_width=2,\n",
    "                line_color=\"red\",\n",
    "                row=row_idx,\n",
    "                col=1,\n",
    "                secondary_y=False,\n",
    "            )\n",
    "\n",
    "        # finally add the ECG wave\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=ts[start:stop],\n",
    "                y=x[start:stop],\n",
    "                name=\"ECG\",\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=primary_color, width=2),\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object IcentiaDataset.uniform_patient_generator at 0x1555511ed480>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BackendRunner = EvbBackend if params.backend == \"evb\" else PcBackend\n",
    "runner = BackendRunner(params=params)\n",
    "\n",
    "# input should be a SignalMetaGenerator\n",
    "patient_ids = datasets[0].get_test_patient_ids()\n",
    "single_pat_gen = datasets[0].uniform_patient_generator(patient_ids=[patient_ids[0]], repeat=False, shuffle=False)\n",
    "single_pat_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = patient_ids[0]\n",
    "segment_id = 0\n",
    "x_start = 0\n",
    "x_end = 5000\n",
    "\n",
    "\n",
    "continuous_gen = datasets[0].signal_label_TimeFrame_generator(single_pat_gen, segment_id=segment_id, frame_start=x_start, frame_end=x_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'datasets/icentia11k/p10000.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontinuous_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tmp\n",
      "File \u001b[0;32m~/heartkit/heartkit/datasets/icentia11k.py:830\u001b[0m, in \u001b[0;36mIcentiaDataset.signal_label_TimeFrame_generator\u001b[0;34m(self, patient_generator, segment_id, frame_start, frame_end)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate random frames using patient generator.\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \n\u001b[1;32m    819\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m    SignalMetaGenerator: Generator of signal and their corresponding label (frame_size, 1)\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# tgt_map = {k: self.class_map.get(v, -1) for (k, v) in HeartRhythmMap.items()}\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# class_map = get_class_mapping(self.num_classes)\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# tgt_map = {k: class_map.get(v, -1) for (k, v) in HeartRhythmMap.items()}\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpatient_generator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m[\u001b[49m\u001b[43msegment_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# get the overall size of current segment, _sID\u001b[39;49;00m\n",
      "File \u001b[0;32m~/heartkit/heartkit/datasets/icentia11k.py:988\u001b[0m, in \u001b[0;36mIcentiaDataset.uniform_patient_generator\u001b[0;34m(self, patient_ids, repeat, shuffle)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m patient_id \u001b[38;5;129;01min\u001b[39;00m patient_ids:\n\u001b[1;32m    987\u001b[0m     pt_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pt_key(patient_id)\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpt_key\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m h5:\n\u001b[1;32m    989\u001b[0m         patient_data \u001b[38;5;241m=\u001b[39m h5[pt_key]\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m patient_id, patient_data\n",
      "File \u001b[0;32m~/.conda/envs/DigitalHealth/lib/python3.11/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.conda/envs/DigitalHealth/lib/python3.11/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'datasets/icentia11k/p10000.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "tmp = next(continuous_gen)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    -1: \"#505050\",  # Grey color for -1\n",
    "    0: \"#11acd5\",  # Blue color for 0\n",
    "    1: \"#ce6cff\",  # Purple color for 1\n",
    "    2: \"#a1d34f\"   # Green color for 2\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_start_end_plot(id, seg_sig_gen, frame_start, frame_end):\n",
    "    color_dict = {\n",
    "        -1: \"#505050\",  # Grey color for -1\n",
    "        0: \"#11acd5\",  # Blue color for 0\n",
    "        1: \"#ce6cff\",  # Purple color for 1\n",
    "        2: \"#a1d34f\"   # Green color for 2\n",
    "    }\n",
    "\n",
    "\n",
    "    # sub_x = \n",
    "    bg_color = \"rgba(38,42,50,1.0)\"\n",
    "    plotly_template = \"plotly_dark\"\n",
    "\n",
    "    n_sample = sub_x.shape[0] / params.frame_size\n",
    "    nrow = int(n_sample/5)\n",
    "    tod = datetime.datetime(2024, 5, 24, random.randint(12, 23), 00)\n",
    "    ts = np.array([tod + datetime.timedelta(seconds=i / params.sampling_rate) for i in range(sub_x.shape[0])])\n",
    "    for i in tqdm(range(0, sub_x.shape[0], params.frame_size), desc=\"Inference\"):\n",
    "        ratios = []\n",
    "        if i % (5*params.frame_size) == 0:\n",
    "\n",
    "            # start a new row for the make_plots\n",
    "            row_idx += 1\n",
    "            # print(row_idx)\n",
    "        # this is [x.shape[0] - 400, x.shape[0]], get the earlier peak, this is the end\n",
    "        if i + params.frame_size > sub_x.shape[0]:\n",
    "            start, stop = sub_x.shape[0] - params.frame_size, sub_x.shape[0]\n",
    "        else:\n",
    "            start, stop = i, i + params.frame_size\n",
    "\n",
    "        # print(\"Before inference this is the ts:\", i, start, stop)\n",
    "        xx = prepare(sub_x[start:stop], sample_rate=params.sampling_rate, preprocesses=params.preprocesses)\n",
    "        runner.set_inputs(xx)\n",
    "        runner.perform_inference()\n",
    "        yy = runner.get_outputs()\n",
    "        # y_orig[start:stop] = \n",
    "        # this is the predicted label for current frame\n",
    "        y_pred[start:stop] = np.argmax(yy, axis=-1).flatten()\n",
    "        # Assuming y_pred and y_orig are numpy arrays\n",
    "        if y_pred[i] == y_orig[i]:\n",
    "            ratios.append(1)\n",
    "        else:\n",
    "            ratios.append(0)\n",
    "\n",
    "        print(np.sum(ratios) / (len(y_pred) / 400))\n",
    "        whole_seg_pred.append(ratios)\n",
    "    \n",
    "\n",
    "    fig = make_subplots(\n",
    "            rows=nrow,\n",
    "            cols=1,\n",
    "            specs=[[{\"colspan\": 1, \"type\": \"xy\", \"secondary_y\": True}]] * nrow,\n",
    "            subplot_titles=(None, None),\n",
    "            horizontal_spacing=0.05,\n",
    "            vertical_spacing=0.1,\n",
    "        )\n",
    "    \n",
    "    fig = visualize_prediction(\n",
    "        fig,\n",
    "        ts,\n",
    "        sub_x,\n",
    "        y_pred, \n",
    "        y_orig,\n",
    "        class_names,\n",
    "        color_dict,\n",
    "        row_idx,\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        template=plotly_template,\n",
    "        height=400*nrow,\n",
    "        plot_bgcolor=bg_color,\n",
    "        paper_bgcolor=bg_color,\n",
    "        margin=dict(l=10, r=10, t=80, b=80),\n",
    "        legend=dict(groupclick=\"toggleitem\"),\n",
    "        title=f\"Patient ID: {id}, Segment ID: {segment_id}\",\n",
    "        title_x=0.5,\n",
    "    )\n",
    "    fig.write_html(params.job_dir / \"longer_demo.html\", include_plotlyjs=\"cdn\", full_html=True)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_idx = 0\n",
    "\n",
    "\n",
    "bg_color = \"rgba(38,42,50,1.0)\"\n",
    "primary_color = \"#11acd5\"\n",
    "plotly_template = \"plotly_dark\"\n",
    "\n",
    "\n",
    "ratios = [] # store whether predctions == ground truth for 60 minutes\n",
    "\n",
    "\n",
    "# maximal length should be 1 minute\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, sub_x.shape[0], params.frame_size), desc=\"Inference\"):\n",
    "    if i % (5*params.frame_size) == 0:\n",
    "        row_idx += 1\n",
    "        print(row_idx)\n",
    "    # this is [x.shape[0] - 400, x.shape[0]], get the earlier peak, this is the end\n",
    "    if i + params.frame_size > sub_x.shape[0]:\n",
    "        start, stop = sub_x.shape[0] - params.frame_size, sub_x.shape[0]\n",
    "    else:\n",
    "        start, stop = i, i + params.frame_size\n",
    "    # print(\"Before inference this is the ts:\", i, start, stop)\n",
    "    xx = prepare(x[start:stop], sample_rate=params.sampling_rate, preprocesses=params.preprocesses)\n",
    "    runner.set_inputs(xx)\n",
    "    runner.perform_inference()\n",
    "    yy = runner.get_outputs()\n",
    "    y_pred[start:stop] = np.argmax(yy, axis=-1).flatten()\n",
    "\n",
    "    fig.add_annotation(\n",
    "        x=ts[start] + (ts[stop-1] - ts[start]) / 2,\n",
    "        y=np.min(x)*0.8,\n",
    "        text=class_names[y_pred[start]],\n",
    "        showarrow=False,\n",
    "        row=row_idx,\n",
    "        col=1,\n",
    "        font=dict(color=color_dict[y_pred[start]]),\n",
    "    )\n",
    "\n",
    "    # predicted results\n",
    "    fig.add_vrect(\n",
    "        x0=ts[start],\n",
    "        x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "        y0=np.min(x)/3+0.2,\n",
    "        # y1=np.max(x[start:stop]) / 2,\n",
    "        y1=np.min(x)/3,  \n",
    "        fillcolor=color_dict[y_pred[start]],\n",
    "        opacity=0.25,\n",
    "        line_width=0,\n",
    "        row=row_idx,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # original results\n",
    "    fig.add_annotation(\n",
    "        x=ts[start] + (ts[stop-1] - ts[start]) / 2,\n",
    "        y=np.max(x),\n",
    "        text=class_names[y_orig[i // 400]],\n",
    "        showarrow=False,\n",
    "        row=row_idx,\n",
    "        col=1,\n",
    "        font=dict(color=color_dict[y_orig[i // 400]]),\n",
    "    )\n",
    "\n",
    "    fig.add_vrect(\n",
    "        x0=ts[start],\n",
    "        x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "        # y0=np.max(x)/2,\n",
    "        y0=0.9,\n",
    "        # y1=np.max(x)*0.8,  \n",
    "        y1=1.1,\n",
    "        fillcolor=color_dict[y_orig[i // 400]],\n",
    "        opacity=0.25,\n",
    "        line_width=0,\n",
    "        row=row_idx,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # predction != original\n",
    "    if y_pred[start] != y_orig[i // 400]:\n",
    "        fig.add_vrect(\n",
    "            x0=ts[start],\n",
    "            x1=ts[stop-1] - datetime.timedelta(seconds=0.1),\n",
    "            # y0=np.max(x)/2,\n",
    "            y0=0.9,\n",
    "            # y1=np.max(x)*0.8,  \n",
    "            y1=1.1,\n",
    "            # annotation_text=class_names[y_pred[start]],\n",
    "            fillcolor=\"red\",\n",
    "            opacity=0.25,\n",
    "            line_width=2,\n",
    "            line_color=\"red\",\n",
    "            row=row_idx,\n",
    "            col=1,\n",
    "            secondary_y=False,\n",
    "        )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ts[start:stop],\n",
    "            y=x[start:stop],\n",
    "            name=\"ECG\",\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=primary_color, width=2),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=row_idx,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )            \n",
    "# END FOR\n",
    "runner.close()\n",
    "\n",
    "    \n",
    "\n",
    "fig.update_layout(\n",
    "    template=plotly_template,\n",
    "    height=400*nrow,\n",
    "    plot_bgcolor=bg_color,\n",
    "    paper_bgcolor=bg_color,\n",
    "    margin=dict(l=10, r=10, t=80, b=80),\n",
    "    legend=dict(groupclick=\"toggleitem\"),\n",
    "    title=f\"Patient ID: {patient_id}, Segment ID: {segment_id}\",\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.write_html(params.job_dir / \"longer_demo.html\", include_plotlyjs=\"cdn\", full_html=True)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DigitalHealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
