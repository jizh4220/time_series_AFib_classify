{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 16:22:22.065647: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 16:22:22.069261: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 16:22:22.106207: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 16:22:22.106235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 16:22:22.107529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-15 16:22:22.114754: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 16:22:22.115513: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 16:22:23.197642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from heartkit.tasks import TaskFactory\n",
    "from typing import Type, TypeVar\n",
    "from argdantic import ArgField, ArgParser\n",
    "from pydantic import BaseModel\n",
    "from heartkit.utils import env_flag, set_random_seed, setup_logger\n",
    "\n",
    "from heartkit.tasks.AFIB_Ident.utils import (\n",
    "    create_model,\n",
    "    load_datasets,\n",
    "    load_test_datasets,\n",
    "    load_train_datasets,\n",
    "    prepare,\n",
    ")\n",
    "\n",
    "from heartkit.defines import (\n",
    "    HKDemoParams\n",
    ")\n",
    "from heartkit.tasks.AFIB_Ident.defines import (\n",
    "    get_class_mapping,\n",
    "    get_class_names,\n",
    "    get_class_shape,\n",
    "    get_classes,\n",
    "    get_feat_shape,\n",
    ")\n",
    "\n",
    "cli = ArgParser()\n",
    "B = TypeVar(\"B\", bound=BaseModel)\n",
    "\n",
    "\n",
    "def parse_content(cls: Type[B], content: str) -> B:\n",
    "    \"\"\"Parse file or raw content into Pydantic model.\n",
    "\n",
    "    Args:\n",
    "        cls (B): Pydantic model subclasss\n",
    "        content (str): File path or raw content\n",
    "\n",
    "    Returns:\n",
    "        B: Pydantic model subclass instance\n",
    "    \"\"\"\n",
    "    if os.path.isfile(content):\n",
    "        with open(content, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "    return cls.model_validate_json(json_data=content)\n",
    "\n",
    "\n",
    "config = 'configs/arrhythmia-100class-2.json'\n",
    "params = parse_content(HKDemoParams, config)\n",
    "\n",
    "\n",
    "params.seed = set_random_seed(params.seed)\n",
    "params.data_parallelism = 8\n",
    "\n",
    "class_names = get_class_names(params.num_classes)\n",
    "class_map = get_class_mapping(params.num_classes)\n",
    "input_spec = (\n",
    "    tf.TensorSpec(shape=get_feat_shape(params.frame_size), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=get_class_shape(params.frame_size, params.num_classes), dtype=tf.int32),\n",
    ")\n",
    "\n",
    "datasets = load_datasets(\n",
    "    ds_path=params.ds_path,\n",
    "    frame_size=params.frame_size,\n",
    "    sampling_rate=params.sampling_rate,\n",
    "    class_map=class_map,\n",
    "    spec=input_spec,\n",
    "    datasets=params.datasets,\n",
    ")\n",
    "\n",
    "# this is where they get the test signal and the label\n",
    "test_x, test_y = load_test_datasets(datasets=datasets, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_ids = datasets[0].get_test_patient_ids()\n",
    "signal_label = next(datasets[0].signal_label_generator(datasets[0].uniform_patient_generator(patient_ids=patient_ids, repeat=False)))\n",
    "x = signal_label[0]\n",
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"rlabels\": shape (20, 2), type \"<i4\">"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "patient_ids = datasets[0].get_test_patient_ids()\n",
    "pat_gen = datasets[0].uniform_patient_generator(patient_ids=patient_ids, repeat=False)\n",
    "first_pat = next(pat_gen)\n",
    "\n",
    "segment = first_pat[1][np.random.choice(list(first_pat[1].keys()))]\n",
    "# rlabels are the rhythm type\n",
    "segment[\"rlabels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlabels = segment[\"rlabels\"][:]\n",
    "rlabels\n",
    "xs, xe, xl = rlabels[0::2, 0], rlabels[1::2, 0], rlabels[0::2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    120  358662  367313  384920  832166  872517  929152  942302  980922\n",
      " 1004133] [ 357063  365728  383353  830248  870657  927440  940660  961648  998137\n",
      " 1048429]\n"
     ]
    }
   ],
   "source": [
    "from enum import IntEnum\n",
    "from heartkit.defines import (\n",
    "    HKDemoParams, HeartBeat, HeartRate, HeartRhythm, HeartSegment\n",
    ")\n",
    "\n",
    "from heartkit.tasks.AFIB_Ident.defines import (\n",
    "    get_class_mapping,\n",
    "    get_class_names,\n",
    "    get_class_shape,\n",
    "    get_classes,\n",
    "    get_feat_shape,\n",
    ")\n",
    "\n",
    "class IcentiaRhythm(IntEnum):\n",
    "    \"\"\"Icentia rhythm labels\"\"\"\n",
    "    noise = 0\n",
    "    normal = 1\n",
    "    afib = 2\n",
    "    aflut = 3\n",
    "    end = 4\n",
    "\n",
    "HeartRhythmMap = {\n",
    "    IcentiaRhythm.noise: HeartRhythm.noise,\n",
    "    IcentiaRhythm.normal: HeartRhythm.normal,\n",
    "    IcentiaRhythm.afib: HeartRhythm.afib,\n",
    "    IcentiaRhythm.aflut: HeartRhythm.aflut,\n",
    "    IcentiaRhythm.end: HeartRhythm.noise,\n",
    "}\n",
    "\n",
    "\n",
    "tgt_labels = list(set(class_map.values()))\n",
    "seg_map: list[str] = list(segment.keys()) # blabel, data, rlabel\n",
    "pt_tgt_seg_map = [[] for _ in tgt_labels]\n",
    "pt_tgt_seg_map\n",
    "\n",
    "class_map = get_class_mapping(2)\n",
    "tgt_map = {k: class_map.get(v, -1) for (k, v) in HeartRhythmMap.items()}\n",
    "input_size = 400\n",
    "# Grab rhythm labels\n",
    "rlabels = segment[\"rlabels\"][:]\n",
    "\n",
    "# Skip if no rhythm labels\n",
    "if not rlabels.shape[0]:\n",
    "    print(\"No rlabel\")\n",
    "rlabels = rlabels[np.where(rlabels[:, 1] != IcentiaRhythm.noise.value)[0]]\n",
    "if not rlabels.shape[0]:\n",
    "    print(\"Only noise\")\n",
    "\n",
    "# Unpack start, end, and label\n",
    "xs, xe, xl = rlabels[0::2, 0], rlabels[1::2, 0], rlabels[0::2, 1]\n",
    "\n",
    "print(xs, xe)\n",
    "# Map labels to target labels\n",
    "xl = np.vectorize(tgt_map.get, otypes=[int])(xl)\n",
    "\n",
    "# Capture segment, start, and end for each target label\n",
    "for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "    idxs = np.where((xe - xs >= input_size) & (xl == tgt_class))\n",
    "    seg_vals = np.vstack((0 * np.ones_like(idxs), xs[idxs], xe[idxs])).T\n",
    "    pt_tgt_seg_map[tgt_idx] += seg_vals.tolist()\n",
    "# END FOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "samples_per_patient = [25, 200][0]\n",
    "num_per_tgt = int(max(1, samples_per_patient / num_classes))\n",
    "samples_per_tgt = num_per_tgt * [num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "pt_tgt_seg_map = [np.array(b) for b in pt_tgt_seg_map]\n",
    "\n",
    "# Grab target segments\n",
    "seg_samples: list[tuple[int, int, int, int]] = []\n",
    "for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "    tgt_segments = pt_tgt_seg_map[tgt_idx]\n",
    "    if not tgt_segments.shape[0]:\n",
    "        continue\n",
    "    tgt_seg_indices: list[int] = random.choices(\n",
    "        np.arange(tgt_segments.shape[0]),\n",
    "        weights=tgt_segments[:, 2] - tgt_segments[:, 1],\n",
    "        k=samples_per_tgt[tgt_idx],\n",
    "    )\n",
    "    for tgt_seg_idx in tgt_seg_indices:\n",
    "        seg_idx, rhy_start, rhy_end = tgt_segments[tgt_seg_idx]\n",
    "        frame_start = np.random.randint(rhy_start, rhy_end - input_size + 1)\n",
    "        frame_end = frame_start + input_size\n",
    "        seg_samples.append((seg_idx, frame_start, frame_end, tgt_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1022, 1422, 0), (0, 86916, 87316, 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(seg_samples)\n",
    "\n",
    "# Yield selected samples for patient\n",
    "for seg_idx, frame_start, frame_end, label in seg_samples:\n",
    "    x: npt.NDArray = segments[seg_map[seg_idx]][\"data\"][frame_start:frame_end].astype(np.float32)\n",
    "    if self.sampling_rate != self.target_rate:\n",
    "        x = pk.signal.resample_signal(x, self.sampling_rate, self.target_rate, axis=0)\n",
    "    yield x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group patient rhythms by type (segment, start, stop, delta)\n",
    "for _, segments in patient_generator:\n",
    "    # This maps segment index to segment key\n",
    "    seg_map: list[str] = list(segments.keys())\n",
    "\n",
    "    pt_tgt_seg_map = [[] for _ in tgt_labels]\n",
    "    for seg_idx, seg_key in enumerate(seg_map):\n",
    "        # Grab rhythm labels\n",
    "        rlabels = segments[seg_key][\"rlabels\"][:]\n",
    "        # Unpack start, end, and label\n",
    "        xs, xe, xl = rlabels[0::2, 0], rlabels[1::2, 0], rlabels[0::2, 1]\n",
    "\n",
    "        # Capture segment, start, and end for each target label\n",
    "        for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "            idxs = np.where((xe - xs >= input_size) & (xl == tgt_class))\n",
    "            seg_vals = np.vstack((seg_idx * np.ones_like(idxs), xs[idxs], xe[idxs])).T\n",
    "            pt_tgt_seg_map[tgt_idx] += seg_vals.tolist()\n",
    "        # END FOR\n",
    "    # END FOR\n",
    "    pt_tgt_seg_map = [np.array(b) for b in pt_tgt_seg_map]\n",
    "\n",
    "    # Grab target segments\n",
    "    seg_samples: list[tuple[int, int, int, int]] = []\n",
    "    for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "        tgt_segments = pt_tgt_seg_map[tgt_idx]\n",
    "        if not tgt_segments.shape[0]:\n",
    "            continue\n",
    "        tgt_seg_indices: list[int] = random.choices(\n",
    "            np.arange(tgt_segments.shape[0]),\n",
    "            weights=tgt_segments[:, 2] - tgt_segments[:, 1],\n",
    "            k=samples_per_tgt[tgt_idx],\n",
    "        )\n",
    "        for tgt_seg_idx in tgt_seg_indices:\n",
    "            seg_idx, rhy_start, rhy_end = tgt_segments[tgt_seg_idx]\n",
    "            frame_start = np.random.randint(rhy_start, rhy_end - input_size + 1)\n",
    "            frame_end = frame_start + input_size\n",
    "            seg_samples.append((seg_idx, frame_start, frame_end, tgt_class))\n",
    "        # END FOR\n",
    "    # END FOR\n",
    "\n",
    "    # Shuffle segments\n",
    "    random.shuffle(seg_samples)\n",
    "\n",
    "    # Yield selected samples for patient\n",
    "    for seg_idx, frame_start, frame_end, label in seg_samples:\n",
    "        x: npt.NDArray = segments[seg_map[seg_idx]][\"data\"][frame_start:frame_end].astype(np.float32)\n",
    "        if self.sampling_rate != self.target_rate:\n",
    "            x = pk.signal.resample_signal(x, self.sampling_rate, self.target_rate, axis=0)\n",
    "        yield x, label\n",
    "    # END FOR\n",
    "# END FOR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DigitalHealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
