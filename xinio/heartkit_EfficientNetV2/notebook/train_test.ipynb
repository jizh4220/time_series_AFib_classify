{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 20:04:44.544139: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-14 20:04:45.316739: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-14 20:04:46.709498: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 20:04:46.709550: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 20:04:46.922623: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 20:04:47.413718: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-14 20:04:47.414394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 20:04:52.757538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy.typing as npt\n",
    "from heartkit.datasets.defines import PatientGenerator, Preprocessor, SampleGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "def default_preprocess(x: npt.NDArray) -> npt.NDArray:\n",
    "    \"\"\"Default identity preprocessing.\"\"\"\n",
    "    return x\n",
    "\n",
    "\n",
    "def _dataset_sample_generator(\n",
    "    self,\n",
    "    patient_ids: npt.NDArray,\n",
    "    samples_per_patient: int | list[int] = 100,\n",
    "    repeat: bool = True,\n",
    "    preprocess: Preprocessor | None = None,\n",
    ") -> SampleGenerator:\n",
    "    \"\"\"Internal sample generator for task.\n",
    "\n",
    "    Args:\n",
    "        patient_ids (npt.NDArray): Patient IDs\n",
    "        samples_per_patient (int | list[int], optional): Samples per patient. Defaults to 100.\n",
    "        repeat (bool, optional): Repeat. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        SampleGenerator: Task sample generator\n",
    "    \"\"\"\n",
    "    patient_generator = self.uniform_patient_generator(patient_ids, repeat=repeat)\n",
    "    data_generator = self.task_data_generator(\n",
    "        patient_generator,\n",
    "        samples_per_patient=samples_per_patient,\n",
    "    )\n",
    "    preprocess_fn = preprocess if preprocess else default_preprocess\n",
    "    num_classes = len(set(self.class_map.values()))\n",
    "    feat_shape = tuple(self.spec[0].shape)\n",
    "\n",
    "    data_generator = map(\n",
    "        lambda x_y: (\n",
    "            preprocess_fn(x_y[0]).reshape(feat_shape),\n",
    "            x_y[0] if num_classes <= 1 else tf.one_hot(x_y[1], num_classes), # x_y[1] should be the corresponding label\n",
    "        ),\n",
    "        data_generator,\n",
    "    )\n",
    "\n",
    "    return data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_data_generator(\n",
    "    self,\n",
    "    patient_generator: PatientGenerator,\n",
    "    samples_per_patient: int | list[int] = 1,\n",
    ") -> SampleGenerator:\n",
    "    \"\"\"Generate frames w/ rhythm labels (e.g. afib) using patient generator.\n",
    "\n",
    "    Args:\n",
    "        patient_generator (PatientGenerator): Patient Generator\n",
    "        samples_per_patient (int | list[int], optional): # samples per patient. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        SampleGenerator: Sample generator\n",
    "\n",
    "    Yields:\n",
    "        Iterator[SampleGenerator]\n",
    "    \"\"\"\n",
    "    # Target labels and mapping\n",
    "    tgt_labels = list(set(self.class_map.values()))\n",
    "\n",
    "    # Convert Icentia labels -> HK labels -> class map labels (-1 indicates not in class map)\n",
    "    tgt_map = {k: self.class_map.get(v, -1) for (k, v) in HeartRhythmMap.items()}\n",
    "    num_classes = len(tgt_labels)\n",
    "\n",
    "    # If samples_per_patient is a list, then it must be the same length as nclasses\n",
    "    if isinstance(samples_per_patient, Iterable):\n",
    "        samples_per_tgt = samples_per_patient\n",
    "    else:\n",
    "        num_per_tgt = int(max(1, samples_per_patient / num_classes))\n",
    "        samples_per_tgt = num_per_tgt * [num_classes]\n",
    "\n",
    "    input_size = int(np.round((self.sampling_rate / self.target_rate) * self.frame_size))\n",
    "\n",
    "    # Group patient rhythms by type (segment, start, stop, delta)\n",
    "    for _, segments in patient_generator:\n",
    "        # This maps segment index to segment key\n",
    "        seg_map: list[str] = list(segments.keys())\n",
    "\n",
    "        pt_tgt_seg_map = [[] for _ in tgt_labels]\n",
    "        for seg_idx, seg_key in enumerate(seg_map):\n",
    "            # Grab rhythm labels\n",
    "            rlabels = segments[seg_key][\"rlabels\"][:]\n",
    "\n",
    "            # Skip if no rhythm labels\n",
    "            if not rlabels.shape[0]:\n",
    "                continue\n",
    "            rlabels = rlabels[np.where(rlabels[:, 1] != IcentiaRhythm.noise.value)[0]]\n",
    "            if not rlabels.shape[0]:\n",
    "                continue\n",
    "\n",
    "            # Unpack start, end, and label\n",
    "            xs, xe, xl = rlabels[0::2, 0], rlabels[1::2, 0], rlabels[0::2, 1]\n",
    "\n",
    "            # Map labels to target labels\n",
    "            xl = np.vectorize(tgt_map.get, otypes=[int])(xl)\n",
    "\n",
    "            # Capture segment, start, and end for each target label\n",
    "            for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "                idxs = np.where((xe - xs >= input_size) & (xl == tgt_class))\n",
    "                seg_vals = np.vstack((seg_idx * np.ones_like(idxs), xs[idxs], xe[idxs])).T\n",
    "                pt_tgt_seg_map[tgt_idx] += seg_vals.tolist()\n",
    "            # END FOR\n",
    "        # END FOR\n",
    "        pt_tgt_seg_map = [np.array(b) for b in pt_tgt_seg_map]\n",
    "\n",
    "        # Grab target segments\n",
    "        seg_samples: list[tuple[int, int, int, int]] = []\n",
    "        for tgt_idx, tgt_class in enumerate(tgt_labels):\n",
    "            tgt_segments = pt_tgt_seg_map[tgt_idx]\n",
    "            if not tgt_segments.shape[0]:\n",
    "                continue\n",
    "            tgt_seg_indices: list[int] = random.choices(\n",
    "                np.arange(tgt_segments.shape[0]),\n",
    "                weights=tgt_segments[:, 2] - tgt_segments[:, 1],\n",
    "                k=samples_per_tgt[tgt_idx],\n",
    "            )\n",
    "            for tgt_seg_idx in tgt_seg_indices:\n",
    "                seg_idx, rhy_start, rhy_end = tgt_segments[tgt_seg_idx]\n",
    "                frame_start = np.random.randint(rhy_start, rhy_end - input_size + 1)\n",
    "                frame_end = frame_start + input_size\n",
    "                seg_samples.append((seg_idx, frame_start, frame_end, tgt_class))\n",
    "            # END FOR\n",
    "        # END FOR\n",
    "\n",
    "        # Shuffle segments\n",
    "        random.shuffle(seg_samples)\n",
    "\n",
    "        # Yield selected samples for patient\n",
    "        for seg_idx, frame_start, frame_end, label in seg_samples:\n",
    "            x: npt.NDArray = segments[seg_map[seg_idx]][\"data\"][frame_start:frame_end].astype(np.float32)\n",
    "            if self.sampling_rate != self.target_rate:\n",
    "                x = pk.signal.resample_signal(x, self.sampling_rate, self.target_rate, axis=0)\n",
    "            yield x, label\n",
    "        # END FOR\n",
    "    # END FOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check it here: heartkit/datasets/dataset.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DigitalHealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
